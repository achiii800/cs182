{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results Analysis Notebook\n",
    "\n",
    "**EECS 182 Final Project - Analyzing Experiment Results**\n",
    "\n",
    "This notebook provides deeper analysis of experimental results, including:\n",
    "- Statistical significance testing\n",
    "- Spectral trajectory analysis\n",
    "- Singular value distribution evolution\n",
    "- Publication-ready figure generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, '..')\n",
    "os.chdir('..')\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from scipy import stats\n",
    "import torch\n",
    "\n",
    "# Set style for publication-quality plots\n",
    "plt.rcParams.update({\n",
    "    'font.size': 11,\n",
    "    'axes.labelsize': 12,\n",
    "    'axes.titlesize': 13,\n",
    "    'legend.fontsize': 10,\n",
    "    'xtick.labelsize': 10,\n",
    "    'ytick.labelsize': 10,\n",
    "    'figure.figsize': (6, 4),\n",
    "    'figure.dpi': 150,\n",
    "    'savefig.dpi': 300,\n",
    "    'savefig.bbox': 'tight',\n",
    "    'axes.grid': True,\n",
    "    'grid.alpha': 0.3,\n",
    "    'axes.spines.top': False,\n",
    "    'axes.spines.right': False,\n",
    "})\n",
    "\n",
    "print(\"Analysis notebook initialized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load experiment results\n",
    "try:\n",
    "    with open('logs/all_experiment_results.json', 'r') as f:\n",
    "        results = json.load(f)\n",
    "    print(\"Loaded experiment results.\")\n",
    "    print(f\"Available experiments: {list(results.keys())}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"No results file found. Run 02_experiments.ipynb first.\")\n",
    "    results = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Statistical Analysis: Multi-Seed Comparison\n",
    "\n",
    "Run multiple seeds to compute confidence intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi-seed experiment runner\n",
    "import torch.nn.functional as F\n",
    "from muon import MuonSGD, SpectralClipSolver, compute_spectral_norms\n",
    "from models import get_model\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def get_loaders(batch_size=128):\n",
    "    transform_train = T.Compose([\n",
    "        T.RandomCrop(32, padding=4),\n",
    "        T.RandomHorizontalFlip(),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616)),\n",
    "    ])\n",
    "    transform_test = T.Compose([\n",
    "        T.ToTensor(),\n",
    "        T.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616)),\n",
    "    ])\n",
    "    \n",
    "    train_set = torchvision.datasets.CIFAR10('./data', train=True, download=True, transform=transform_train)\n",
    "    test_set = torchvision.datasets.CIFAR10('./data', train=False, download=True, transform=transform_test)\n",
    "    \n",
    "    return (\n",
    "        DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=2, drop_last=True),\n",
    "        DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "    )\n",
    "\n",
    "train_loader, test_loader = get_loaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_with_seed(model_name, optimizer_type, inner_solver, lr, epochs, seed, spectral_budget=0.1):\n",
    "    \"\"\"Run a single training run with given seed.\"\"\"\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    \n",
    "    model = get_model(model_name).to(device)\n",
    "    \n",
    "    if optimizer_type == 'muon_sgd':\n",
    "        from muon import get_inner_solver\n",
    "        solver = get_inner_solver(inner_solver) if inner_solver != 'none' else None\n",
    "        optimizer = MuonSGD(\n",
    "            model.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4,\n",
    "            spectral_budget=spectral_budget if solver else None,\n",
    "            inner_solver=solver\n",
    "        )\n",
    "    else:\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=5e-4)\n",
    "    \n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "    \n",
    "    history = []\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        # Train\n",
    "        model.train()\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            loss = F.cross_entropy(model(x), y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Eval\n",
    "        model.eval()\n",
    "        correct, total = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in test_loader:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                correct += (model(x).argmax(1) == y).sum().item()\n",
    "                total += y.size(0)\n",
    "        \n",
    "        val_acc = correct / total\n",
    "        spec_norms = compute_spectral_norms(model)\n",
    "        max_spec = max(spec_norms.values()) if spec_norms else 0\n",
    "        \n",
    "        history.append({'epoch': epoch, 'val_acc': val_acc, 'max_spec': max_spec})\n",
    "    \n",
    "    return history\n",
    "\n",
    "print(\"Multi-seed runner ready.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run multi-seed experiment\n",
    "NUM_SEEDS = 3  # Increase for better statistics\n",
    "EPOCHS = 10\n",
    "\n",
    "configs = [\n",
    "    ('SGD', 'sgd', 'none'),\n",
    "    ('MuonSGD', 'muon_sgd', 'spectral_clip'),\n",
    "]\n",
    "\n",
    "multi_seed_results = {}\n",
    "\n",
    "for name, opt, solver in configs:\n",
    "    print(f\"\\nRunning {name} across {NUM_SEEDS} seeds...\")\n",
    "    seed_histories = []\n",
    "    \n",
    "    for seed in range(NUM_SEEDS):\n",
    "        print(f\"  Seed {seed}...\", end=' ')\n",
    "        history = run_with_seed('small_cnn', opt, solver, lr=0.1, epochs=EPOCHS, seed=seed)\n",
    "        seed_histories.append(history)\n",
    "        print(f\"Final acc: {history[-1]['val_acc']:.4f}\")\n",
    "    \n",
    "    multi_seed_results[name] = seed_histories\n",
    "\n",
    "print(\"\\nMulti-seed experiments complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute statistics and plot with error bars\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "colors = {'SGD': 'tab:blue', 'MuonSGD': 'tab:orange'}\n",
    "\n",
    "for name, histories in multi_seed_results.items():\n",
    "    epochs = [h[0]['epoch'] for h in histories for _ in range(len(histories[0]))]\n",
    "    epochs = np.array([h['epoch'] for h in histories[0]])\n",
    "    \n",
    "    # Stack all seeds\n",
    "    acc_matrix = np.array([[h['val_acc'] for h in seed_hist] for seed_hist in histories])\n",
    "    spec_matrix = np.array([[h['max_spec'] for h in seed_hist] for seed_hist in histories])\n",
    "    \n",
    "    # Mean and std\n",
    "    acc_mean = acc_matrix.mean(axis=0)\n",
    "    acc_std = acc_matrix.std(axis=0)\n",
    "    spec_mean = spec_matrix.mean(axis=0)\n",
    "    spec_std = spec_matrix.std(axis=0)\n",
    "    \n",
    "    # Plot accuracy\n",
    "    axes[0].plot(epochs, acc_mean, color=colors[name], label=name, linewidth=2)\n",
    "    axes[0].fill_between(epochs, acc_mean - acc_std, acc_mean + acc_std,\n",
    "                         color=colors[name], alpha=0.2)\n",
    "    \n",
    "    # Plot spectral norm\n",
    "    axes[1].plot(epochs, spec_mean, color=colors[name], label=name, linewidth=2)\n",
    "    axes[1].fill_between(epochs, spec_mean - spec_std, spec_mean + spec_std,\n",
    "                         color=colors[name], alpha=0.2)\n",
    "\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Validation Accuracy')\n",
    "axes[0].set_title('Accuracy (mean ± std over seeds)')\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Max Spectral Norm')\n",
    "axes[1].set_title('Spectral Norm (mean ± std over seeds)')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('logs/multi_seed_comparison.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "# Statistical test\n",
    "sgd_final = [h[-1]['val_acc'] for h in multi_seed_results['SGD']]\n",
    "muon_final = [h[-1]['val_acc'] for h in multi_seed_results['MuonSGD']]\n",
    "\n",
    "t_stat, p_value = stats.ttest_ind(sgd_final, muon_final)\n",
    "print(f\"\\nFinal accuracy comparison (t-test):\")\n",
    "print(f\"  SGD:     {np.mean(sgd_final):.4f} ± {np.std(sgd_final):.4f}\")\n",
    "print(f\"  MuonSGD: {np.mean(muon_final):.4f} ± {np.std(muon_final):.4f}\")\n",
    "print(f\"  t-stat: {t_stat:.3f}, p-value: {p_value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Singular Value Distribution Analysis\n",
    "\n",
    "Examine how the full singular value spectrum evolves during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track full singular value spectrum during training\n",
    "from muon import compute_all_singular_values\n",
    "\n",
    "def train_and_track_spectrum(model_name, optimizer_type, inner_solver, epochs=10, seed=42):\n",
    "    \"\"\"Train and record singular value spectrum at each epoch.\"\"\"\n",
    "    torch.manual_seed(seed)\n",
    "    model = get_model(model_name).to(device)\n",
    "    \n",
    "    if optimizer_type == 'muon_sgd':\n",
    "        from muon import get_inner_solver\n",
    "        solver = get_inner_solver(inner_solver)\n",
    "        optimizer = MuonSGD(\n",
    "            model.parameters(), lr=0.1, momentum=0.9,\n",
    "            spectral_budget=0.1, inner_solver=solver\n",
    "        )\n",
    "    else:\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
    "    \n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "    \n",
    "    # Find a Linear layer to track\n",
    "    target_layer = None\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, torch.nn.Linear):\n",
    "            target_layer = name\n",
    "            break\n",
    "    \n",
    "    spectrum_history = []\n",
    "    \n",
    "    # Initial spectrum\n",
    "    sv = compute_all_singular_values(model, target_layer)\n",
    "    if sv is not None:\n",
    "        spectrum_history.append(sv.cpu().numpy())\n",
    "    \n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            loss = F.cross_entropy(model(x), y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Record spectrum\n",
    "        sv = compute_all_singular_values(model, target_layer)\n",
    "        if sv is not None:\n",
    "            spectrum_history.append(sv.cpu().numpy())\n",
    "    \n",
    "    return spectrum_history, target_layer\n",
    "\n",
    "print(\"Tracking SGD spectrum...\")\n",
    "sgd_spectrum, layer_name = train_and_track_spectrum('small_cnn', 'sgd', 'none', epochs=10)\n",
    "\n",
    "print(\"Tracking MuonSGD spectrum...\")\n",
    "muon_spectrum, _ = train_and_track_spectrum('small_cnn', 'muon_sgd', 'spectral_clip', epochs=10)\n",
    "\n",
    "print(f\"\\nTracked layer: {layer_name}\")\n",
    "print(f\"Spectrum length: {len(sgd_spectrum[0])} singular values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot singular value evolution\n",
    "fig, axes = plt.subplots(1, 3, figsize=(14, 4))\n",
    "\n",
    "# Full spectrum at final epoch\n",
    "axes[0].semilogy(sgd_spectrum[-1], 'b-', label='SGD', linewidth=2)\n",
    "axes[0].semilogy(muon_spectrum[-1], 'r-', label='MuonSGD', linewidth=2)\n",
    "axes[0].set_xlabel('Singular Value Index')\n",
    "axes[0].set_ylabel('Singular Value (log scale)')\n",
    "axes[0].set_title(f'Final Spectrum ({layer_name})')\n",
    "axes[0].legend()\n",
    "\n",
    "# σ_max over time\n",
    "sgd_sigma_max = [s[0] for s in sgd_spectrum]\n",
    "muon_sigma_max = [s[0] for s in muon_spectrum]\n",
    "axes[1].plot(sgd_sigma_max, 'b-', label='SGD', linewidth=2)\n",
    "axes[1].plot(muon_sigma_max, 'r-', label='MuonSGD', linewidth=2)\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('σ_max')\n",
    "axes[1].set_title('Top Singular Value Evolution')\n",
    "axes[1].legend()\n",
    "\n",
    "# Condition number (σ_max / σ_min) over time\n",
    "sgd_condition = [s[0] / (s[-1] + 1e-10) for s in sgd_spectrum]\n",
    "muon_condition = [s[0] / (s[-1] + 1e-10) for s in muon_spectrum]\n",
    "axes[2].semilogy(sgd_condition, 'b-', label='SGD', linewidth=2)\n",
    "axes[2].semilogy(muon_condition, 'r-', label='MuonSGD', linewidth=2)\n",
    "axes[2].set_xlabel('Epoch')\n",
    "axes[2].set_ylabel('Condition Number (log)')\n",
    "axes[2].set_title('Matrix Conditioning Over Training')\n",
    "axes[2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('logs/singular_value_analysis.png', dpi=150)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nFinal condition numbers:\")\n",
    "print(f\"  SGD:     {sgd_condition[-1]:.2f}\")\n",
    "print(f\"  MuonSGD: {muon_condition[-1]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Inner Solver Convergence Analysis\n",
    "\n",
    "Analyze how different inner solvers converge to the constraint-satisfying solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test inner solver behavior on synthetic gradient\n",
    "from muon import (\n",
    "    SpectralClipSolver, FrankWolfeSolver, DualAscentSolver,\n",
    "    QuasiNewtonDualSolver, ADMMSolver\n",
    ")\n",
    "\n",
    "# Create synthetic test case\n",
    "torch.manual_seed(42)\n",
    "m, n = 64, 128\n",
    "W = torch.randn(m, n)  # Weight matrix\n",
    "G = torch.randn(m, n) * 0.5  # Gradient (proposed update)\n",
    "\n",
    "budget = 0.1\n",
    "\n",
    "print(f\"Test case: W shape = {W.shape}, budget = {budget}\")\n",
    "print(f\"Original ||G||_2 = {torch.linalg.matrix_norm(G, ord=2).item():.4f}\")\n",
    "\n",
    "solvers = {\n",
    "    'SpectralClip': SpectralClipSolver(),\n",
    "    'FrankWolfe (5 iter)': FrankWolfeSolver(max_iters=5),\n",
    "    'FrankWolfe (20 iter)': FrankWolfeSolver(max_iters=20),\n",
    "    'DualAscent': DualAscentSolver(max_iters=20),\n",
    "    'QuasiNewton': QuasiNewtonDualSolver(max_iters=15),\n",
    "    'ADMM': ADMMSolver(max_iters=20),\n",
    "}\n",
    "\n",
    "print(\"\\nSolver results:\")\n",
    "print(\"-\" * 50)\n",
    "for name, solver in solvers.items():\n",
    "    result = solver(W, G, budget)\n",
    "    sigma = torch.linalg.matrix_norm(result, ord=2).item()\n",
    "    obj = torch.sum(G * result).item()  # Linear objective\n",
    "    print(f\"{name:25s}: ||Δ||_2 = {sigma:.4f}, <G,Δ> = {obj:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize solver outputs\n",
    "fig, axes = plt.subplots(2, 3, figsize=(12, 8))\n",
    "\n",
    "for ax, (name, solver) in zip(axes.flatten(), solvers.items()):\n",
    "    result = solver(W, G, budget)\n",
    "    \n",
    "    # Show singular values of the result\n",
    "    sv = torch.linalg.svdvals(result).numpy()\n",
    "    ax.bar(range(len(sv)), sv, alpha=0.7)\n",
    "    ax.axhline(budget, color='r', linestyle='--', label=f'Budget = {budget}')\n",
    "    ax.set_xlabel('Singular Value Index')\n",
    "    ax.set_ylabel('Singular Value')\n",
    "    ax.set_title(f'{name}')\n",
    "    ax.set_xlim(-1, 20)  # Show first 20\n",
    "    ax.legend(fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('logs/inner_solver_spectra.png', dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Publication-Ready Figures\n",
    "\n",
    "Generate final figures for the project report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main comparison figure (2x2 layout)\n",
    "if results is not None and 'solver_comparison' in results:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(10, 8))\n",
    "    \n",
    "    solver_data = results['solver_comparison']\n",
    "    colors = plt.cm.Set2(np.linspace(0, 1, len(solver_data)))\n",
    "    \n",
    "    for (name, history), color in zip(solver_data.items(), colors):\n",
    "        epochs = [h['epoch'] for h in history]\n",
    "        \n",
    "        # Val loss\n",
    "        axes[0, 0].plot(epochs, [h['val_loss'] for h in history], \n",
    "                        label=name, color=color, linewidth=1.5)\n",
    "        # Val acc\n",
    "        axes[0, 1].plot(epochs, [h['val_acc'] for h in history],\n",
    "                        label=name, color=color, linewidth=1.5)\n",
    "        # Spectral norm\n",
    "        axes[1, 0].plot(epochs, [h['max_spectral_norm'] for h in history],\n",
    "                        label=name, color=color, linewidth=1.5)\n",
    "        # Sharpness\n",
    "        axes[1, 1].plot(epochs, [h['sharpness'] for h in history],\n",
    "                        label=name, color=color, linewidth=1.5)\n",
    "    \n",
    "    axes[0, 0].set_ylabel('Validation Loss')\n",
    "    axes[0, 0].set_title('(a) Validation Loss')\n",
    "    \n",
    "    axes[0, 1].set_ylabel('Validation Accuracy')\n",
    "    axes[0, 1].set_title('(b) Validation Accuracy')\n",
    "    \n",
    "    axes[1, 0].set_xlabel('Epoch')\n",
    "    axes[1, 0].set_ylabel('Max Spectral Norm')\n",
    "    axes[1, 0].set_title('(c) Spectral Norm Control')\n",
    "    \n",
    "    axes[1, 1].set_xlabel('Epoch')\n",
    "    axes[1, 1].set_ylabel('Sharpness')\n",
    "    axes[1, 1].set_title('(d) Loss Landscape Sharpness')\n",
    "    \n",
    "    # Single legend\n",
    "    handles, labels = axes[0, 0].get_legend_handles_labels()\n",
    "    fig.legend(handles, labels, loc='upper center', ncol=4, bbox_to_anchor=(0.5, 1.02))\n",
    "    \n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    plt.savefig('logs/figure_main_comparison.pdf', dpi=300)\n",
    "    plt.savefig('logs/figure_main_comparison.png', dpi=300)\n",
    "    plt.show()\n",
    "    print(\"Saved: logs/figure_main_comparison.pdf\")\n",
    "else:\n",
    "    print(\"Run experiments first to generate this figure.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Width transfer figure\n",
    "if results is not None and 'width_transfer_muon' in results:\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    \n",
    "    muon_data = results['width_transfer_muon']\n",
    "    sgd_data = results['width_transfer_sgd']\n",
    "    \n",
    "    widths = sorted([float(w) for w in muon_data.keys()])\n",
    "    muon_accs = [muon_data[str(w)][-1]['val_acc'] for w in widths]\n",
    "    sgd_accs = [sgd_data[str(w)][-1]['val_acc'] for w in widths]\n",
    "    \n",
    "    ax.plot(widths, muon_accs, 'o-', label='MuonSGD (spectral constraint)',\n",
    "            markersize=12, linewidth=2.5, color='tab:blue')\n",
    "    ax.plot(widths, sgd_accs, 's--', label='SGD (baseline)',\n",
    "            markersize=10, linewidth=2, color='tab:orange')\n",
    "    \n",
    "    ax.set_xlabel('Width Multiplier', fontsize=12)\n",
    "    ax.set_ylabel('Final Validation Accuracy', fontsize=12)\n",
    "    ax.set_title('Hyperparameter Transfer Across Widths', fontsize=14)\n",
    "    ax.legend(fontsize=11)\n",
    "    \n",
    "    # Add variance annotation\n",
    "    muon_std = np.std(muon_accs)\n",
    "    sgd_std = np.std(sgd_accs)\n",
    "    ax.annotate(f'MuonSGD σ = {muon_std:.4f}\\nSGD σ = {sgd_std:.4f}',\n",
    "                xy=(0.95, 0.05), xycoords='axes fraction',\n",
    "                ha='right', va='bottom',\n",
    "                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('logs/figure_width_transfer.pdf', dpi=300)\n",
    "    plt.savefig('logs/figure_width_transfer.png', dpi=300)\n",
    "    plt.show()\n",
    "    print(\"Saved: logs/figure_width_transfer.pdf\")\n",
    "else:\n",
    "    print(\"Run experiments first to generate this figure.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Results Summary Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate results summary table\n",
    "if results is not None and 'solver_comparison' in results:\n",
    "    summary_data = []\n",
    "    \n",
    "    for name, history in results['solver_comparison'].items():\n",
    "        final = history[-1]\n",
    "        best_acc = max(h['val_acc'] for h in history)\n",
    "        final_spec = final['max_spectral_norm']\n",
    "        final_sharp = final['sharpness']\n",
    "        \n",
    "        summary_data.append({\n",
    "            'Method': name,\n",
    "            'Final Val Acc': f\"{final['val_acc']:.4f}\",\n",
    "            'Best Val Acc': f\"{best_acc:.4f}\",\n",
    "            'Final σ_max': f\"{final_spec:.3f}\",\n",
    "            'Final Sharpness': f\"{final_sharp:.4f}\",\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(summary_data)\n",
    "    print(\"\\nResults Summary (ResNet-18 on CIFAR-10):\")\n",
    "    print(\"=\" * 80)\n",
    "    print(df.to_string(index=False))\n",
    "    \n",
    "    # Save to CSV\n",
    "    df.to_csv('logs/results_summary.csv', index=False)\n",
    "    print(\"\\nSaved: logs/results_summary.csv\")\n",
    "else:\n",
    "    print(\"Run experiments first to generate summary.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Key Takeaways\n",
    "\n",
    "### Observations from Experiments:\n",
    "\n",
    "1. **Spectral Norm Control**: MuonSGD effectively controls the maximum singular values of weight matrices during training, while vanilla SGD allows unbounded growth.\n",
    "\n",
    "2. **Inner Solver Trade-offs**:\n",
    "   - **SpectralClip**: Fastest, but may distort gradient direction\n",
    "   - **DualAscent**: Good balance of accuracy and speed\n",
    "   - **QuasiNewton**: Faster convergence on the dual, but more complex\n",
    "   - **FrankWolfe**: Produces low-rank updates, projection-free\n",
    "   - **ADMM**: Clean separation of constraints, adaptive ρ helps\n",
    "\n",
    "3. **Width Transfer**: Spectral constraints reduce variance in final accuracy across different model widths, supporting better hyperparameter transfer.\n",
    "\n",
    "4. **Stability**: MuonSGD may extend the stable learning rate region compared to vanilla SGD.\n",
    "\n",
    "### Connections to Theory:\n",
    "\n",
    "- Spectral norm constraints provide a **Lipschitz bound** on layer-wise transformations\n",
    "- Lower sharpness correlates with the **flatness of minima** hypothesis\n",
    "- Width-independent hyperparameters align with **muP scaling** principles\n",
    "\n",
    "### Future Work:\n",
    "\n",
    "- Extend to larger-scale transformers\n",
    "- Combine with manifold constraints (Stiefel)\n",
    "- Investigate connections to implicit regularization"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
