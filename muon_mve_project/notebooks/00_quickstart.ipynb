{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸš€ Muon MVE - Quick Start (Colab Ready)\n",
    "\n",
    "**EECS 182 Final Project: Spectral-Norm Constrained Optimization**\n",
    "\n",
    "This notebook provides a quick, self-contained demo that runs in Google Colab.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Setup (run this cell first!)\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# If running in Colab, clone the repo\n",
    "if 'google.colab' in sys.modules:\n",
    "    print(\"Running in Colab - setting up environment...\")\n",
    "    # Uncomment and modify if you have a GitHub repo:\n",
    "    # !git clone https://github.com/yourusername/muon_mve_project.git\n",
    "    # %cd muon_mve_project\n",
    "    # !pip install -q -r requirements.txt\n",
    "    print(\"Note: Upload the project files or clone from your repo.\")\n",
    "else:\n",
    "    # Local setup\n",
    "    os.chdir('..')  # Assumes running from notebooks/ directory\n",
    "\n",
    "# Check GPU\n",
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if device.type == 'cuda':\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Import modules\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Import our modules\n",
    "try:\n",
    "    from muon import MuonSGD, SpectralClipSolver, compute_spectral_norms\n",
    "    from models import get_model\n",
    "    print(\"âœ“ Successfully imported muon modules\")\n",
    "except ImportError as e:\n",
    "    print(f\"Import error: {e}\")\n",
    "    print(\"Make sure you're in the project directory or have uploaded the files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Load CIFAR-10\n",
    "transform_train = T.Compose([\n",
    "    T.RandomCrop(32, padding=4),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616)),\n",
    "])\n",
    "transform_test = T.Compose([\n",
    "    T.ToTensor(),\n",
    "    T.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616)),\n",
    "])\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR10('./data', train=True, download=True, transform=transform_train)\n",
    "test_set = torchvision.datasets.CIFAR10('./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=128, shuffle=True, num_workers=2, drop_last=True)\n",
    "test_loader = DataLoader(test_set, batch_size=128, shuffle=False, num_workers=2)\n",
    "\n",
    "print(f\"âœ“ Loaded CIFAR-10: {len(train_set)} train, {len(test_set)} test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Quick Demo - Compare SGD vs MuonSGD\n",
    "\n",
    "EPOCHS = 5  # Quick demo; increase for real experiments\n",
    "\n",
    "def train_and_evaluate(model, optimizer, scheduler, epochs):\n",
    "    \"\"\"Train model and return history.\"\"\"\n",
    "    history = {'train_loss': [], 'val_acc': [], 'max_spec': []}\n",
    "    \n",
    "    for epoch in range(1, epochs + 1):\n",
    "        # Train\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            loss = F.cross_entropy(model(x), y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Evaluate\n",
    "        model.eval()\n",
    "        correct, total = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in test_loader:\n",
    "                x, y = x.to(device), y.to(device)\n",
    "                correct += (model(x).argmax(1) == y).sum().item()\n",
    "                total += y.size(0)\n",
    "        \n",
    "        val_acc = correct / total\n",
    "        spec_norms = compute_spectral_norms(model)\n",
    "        max_spec = max(spec_norms.values()) if spec_norms else 0\n",
    "        \n",
    "        history['train_loss'].append(total_loss / len(train_loader))\n",
    "        history['val_acc'].append(val_acc)\n",
    "        history['max_spec'].append(max_spec)\n",
    "        \n",
    "        print(f\"  Epoch {epoch}: loss={history['train_loss'][-1]:.4f}, \"\n",
    "              f\"acc={val_acc:.4f}, Ïƒ_max={max_spec:.3f}\")\n",
    "    \n",
    "    return history\n",
    "\n",
    "# Train with SGD\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Training with SGD (baseline)\")\n",
    "print(\"=\"*50)\n",
    "torch.manual_seed(42)\n",
    "model_sgd = get_model('small_cnn').to(device)\n",
    "opt_sgd = torch.optim.SGD(model_sgd.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
    "sched_sgd = torch.optim.lr_scheduler.CosineAnnealingLR(opt_sgd, T_max=EPOCHS)\n",
    "history_sgd = train_and_evaluate(model_sgd, opt_sgd, sched_sgd, EPOCHS)\n",
    "\n",
    "# Train with MuonSGD\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Training with MuonSGD (spectral constraint)\")\n",
    "print(\"=\"*50)\n",
    "torch.manual_seed(42)\n",
    "model_muon = get_model('small_cnn').to(device)\n",
    "opt_muon = MuonSGD(\n",
    "    model_muon.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4,\n",
    "    spectral_budget=0.1, inner_solver=SpectralClipSolver()\n",
    ")\n",
    "sched_muon = torch.optim.lr_scheduler.CosineAnnealingLR(opt_muon, T_max=EPOCHS)\n",
    "history_muon = train_and_evaluate(model_muon, opt_muon, sched_muon, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Visualize Results\n",
    "fig, axes = plt.subplots(1, 3, figsize=(14, 4))\n",
    "\n",
    "epochs = range(1, EPOCHS + 1)\n",
    "\n",
    "# Loss\n",
    "axes[0].plot(epochs, history_sgd['train_loss'], 'b-', label='SGD', linewidth=2)\n",
    "axes[0].plot(epochs, history_muon['train_loss'], 'r-', label='MuonSGD', linewidth=2)\n",
    "axes[0].set_xlabel('Epoch')\n",
    "axes[0].set_ylabel('Training Loss')\n",
    "axes[0].set_title('Training Loss')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy\n",
    "axes[1].plot(epochs, history_sgd['val_acc'], 'b-', label='SGD', linewidth=2)\n",
    "axes[1].plot(epochs, history_muon['val_acc'], 'r-', label='MuonSGD', linewidth=2)\n",
    "axes[1].set_xlabel('Epoch')\n",
    "axes[1].set_ylabel('Validation Accuracy')\n",
    "axes[1].set_title('Validation Accuracy')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Spectral Norm\n",
    "axes[2].plot(epochs, history_sgd['max_spec'], 'b-', label='SGD', linewidth=2)\n",
    "axes[2].plot(epochs, history_muon['max_spec'], 'r-', label='MuonSGD', linewidth=2)\n",
    "axes[2].set_xlabel('Epoch')\n",
    "axes[2].set_ylabel('Max Spectral Norm')\n",
    "axes[2].set_title('Spectral Norm Control')\n",
    "axes[2].legend()\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Summary\")\n",
    "print(\"=\"*50)\n",
    "print(f\"SGD     - Final Acc: {history_sgd['val_acc'][-1]:.4f}, Final Ïƒ_max: {history_sgd['max_spec'][-1]:.3f}\")\n",
    "print(f\"MuonSGD - Final Acc: {history_muon['val_acc'][-1]:.4f}, Final Ïƒ_max: {history_muon['max_spec'][-1]:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ðŸŽ¯ Key Observations\n",
    "\n",
    "1. **Spectral Norm Control**: MuonSGD keeps the spectral norms bounded, while SGD allows them to grow.\n",
    "\n",
    "2. **Comparable Accuracy**: Despite the constraint, MuonSGD achieves similar accuracy to SGD.\n",
    "\n",
    "3. **Stability**: The spectral constraint provides a Lipschitz bound on layer-wise transformations.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“š Next Steps\n",
    "\n",
    "1. **More epochs**: Run for 50-100 epochs for full convergence\n",
    "2. **Different architectures**: Try `resnet18`, `tiny_vit`, or `mlp_mixer`\n",
    "3. **Different solvers**: Compare `spectral_clip`, `dual_ascent`, `frank_wolfe`, etc.\n",
    "4. **Width transfer**: Test if hyperparameters transfer across model widths\n",
    "\n",
    "See the other notebooks for comprehensive experiments!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bonus: Try different inner solvers\n",
    "from muon import get_inner_solver, SOLVER_REGISTRY\n",
    "\n",
    "print(\"Available inner solvers:\")\n",
    "for name in SOLVER_REGISTRY.keys():\n",
    "    print(f\"  - {name}\")\n",
    "\n",
    "# Example: Try Frank-Wolfe solver\n",
    "print(\"\\nTrying Frank-Wolfe solver...\")\n",
    "fw_solver = get_inner_solver('frank_wolfe', max_iters=5)\n",
    "print(f\"Created: {type(fw_solver).__name__}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
